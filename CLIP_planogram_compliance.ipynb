{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install \"torch>=2.2\" \"transformers>=4.45\" pillow faiss-cpu numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np, torch\n",
        "from PIL import Image\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL_ID = \"openai/clip-vit-base-patch32\"  # CLIP model\n",
        "\n",
        "processor = CLIPProcessor.from_pretrained(MODEL_ID)\n",
        "model = CLIPModel.from_pretrained(MODEL_ID).to(DEVICE).eval()\n",
        "\n",
        "@torch.inference_mode()\n",
        "def embed_image(path: str) -> np.ndarray:\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    inputs = processor(images=img, return_tensors=\"pt\").to(DEVICE)\n",
        "    out = model.get_image_features(**inputs)\n",
        "    vec = torch.nn.functional.normalize(out.squeeze(0), dim=0)\n",
        "    return vec.cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ref_paths = [\n",
        "    \"images/7up_bottle.jpg\",\n",
        "    \"images/coke_zero.jpg\", \n",
        "    \"images/coke.jpg\",\n",
        "    \"images/pepsi_bottle.jpg\",\n",
        "    \"images/pepsi.jpg\",\n",
        "    \"images/sprite.jpg\"\n",
        "]\n",
        "\n",
        "ref_vecs = np.stack([embed_image(p) for p in ref_paths], axis=0)\n",
        "np.savez(\"clip_refs.npz\", paths=np.array(ref_paths), vecs=ref_vecs)\n",
        "print(\"Saved 6 embeddings → clip_refs.npz\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "q = embed_image(\"images/pepsi_test.jpg\")\n",
        "sims = ref_vecs @ q            # both are L2-normalized → cosine similarity\n",
        "best = int(np.argmax(sims))\n",
        "top3_idx = np.argsort(-sims)[:3]\n",
        "print(\"Most similar:\", ref_paths[best], \"score:\", float(sims[best]))\n",
        "print(\"Top-3:\", [(ref_paths[i], float(sims[i])) for i in top3_idx])\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
